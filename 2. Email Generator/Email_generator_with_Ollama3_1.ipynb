{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FwjHBMmWEnIX",
    "outputId": "bcc75bf1-e6e6-4966-c942-1923e2103f10"
   },
   "outputs": [],
   "source": [
    "#3.11 version\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv() # loading the env key\n",
    "from langchain_groq import ChatGroq\n",
    "import os\n",
    "GROK_API_KEY = os.getenv(\"GROK_API_KEY\")\n",
    "\n",
    "llm = ChatGroq(\n",
    "    temperature = 0,\n",
    "    groq_api_key = GROK_API_KEY,\n",
    "    model_name = 'llama-3.1-70b-versatile')\n",
    "\n",
    "response = llm.invoke(\"India won world cup on 2017 ..\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GROK_API_KEY = os.getenv(\"GROK_API_KEY\")\n",
    "print(GROK_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uw4D_vsXHrx4"
   },
   "outputs": [],
   "source": [
    "# !pip install langchain_community\n",
    "# !pip install langchain_groq\n",
    "# !pip install chromadb\n",
    "# pip show langchain\n",
    "# pip install --upgrade langchain\n",
    "# pip show sqlalchemy\n",
    "# pip install --upgrade sqlalchemy\n",
    "# pip install --upgrade langchain_community\n",
    "# pip show langchain_community\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YP1cH2vRE-uq",
    "outputId": "bda00024-3faa-45bc-ba30-a6633e34adf0"
   },
   "outputs": [],
   "source": [
    "import langchain \n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "loader = WebBaseLoader(\"https://jobs.nike.com/job/R-41251\")\n",
    "page_data = loader.load().pop().page_content\n",
    "print(page_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XmgjoMrTLQT9"
   },
   "source": [
    "#### In Chat-GPT I will give extracted job posting. can you extract the skills, roles and description\n",
    "\n",
    " Output from chat-gpt -- Skills:\n",
    "\n",
    "    Proficiency in Python for developing robust, maintainable, and extendable code\n",
    "    Strong background in algorithms and data structures\n",
    "    AWS (Amazon Web Services) hands-on experience\n",
    "    Database technology knowledge, especially with Postgres and Redis\n",
    "    Data processing tools like EMR\n",
    "    Experience in containerization (Docker) and CI/CD automation\n",
    "    Agile and test-driven development expertise\n",
    "    Data engineering skills, including working with ETL pipelines and SQL\n",
    "    MLOps, API development, and mathematical optimization\n",
    "    Familiarity with Spark, Kubernetes, Jenkins, Databricks, and Terraform\n",
    "    Effective communication skills\n",
    "\n",
    "Role:\n",
    "\n",
    "Senior Machine Learning Engineer\n",
    "\n",
    "Responsibilities include:\n",
    "\n",
    "    Developing advanced analytics and machine learning solutions\n",
    "    Designing and implementing scalable applications for data-driven decision-making\n",
    "    Contributing to advanced analytics and ML platforms\n",
    "    Leading projects end-to-end with a focus on the software development lifecycle\n",
    "    Providing technical vision and guidance to the team\n",
    "    Collaborating with global teams in a diverse, inclusive environment\n",
    "\n",
    "Job Description:\n",
    "\n",
    "As a Senior ML Engineer, you’ll be part of Nike’s AI/ML team, working to solve large-scale machine learning challenges. This role involves creating prediction models and optimization programs, contributing to both analytics and ML platforms, and working with a global team across multiple locations. The position values a collaborative, intellectually curious culture that supports continuous learning and knowledge-sharing within Nike and the broader community.\n",
    "Additional Information:\n",
    "\n",
    "    Location: Beaverton, Oregon (Open to remote, with restrictions for certain states)\n",
    "    Salary range: $99,500 - $222,900"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eMOAnE2YFPN7",
    "outputId": "1a8c0e47-9f5b-4a11-f755-30ca4a84b9da"
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt_extract = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    ### SCRAPED TEXT FROM WEBSITE\n",
    "    {page_data}\n",
    "    ### INSTRUCTION\n",
    "    The scraped text from the career's page of a website.\n",
    "    Your job is to extract the job posting and return them in JSON format containing the\n",
    "    following keys: 'role', 'experience', 'skills' and 'description'.\n",
    "    Only return the valid JSON.\n",
    "    ### VALIDA JSON (No presemble):\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "chain_extract = prompt_extract | llm #This will form chain\n",
    "response = chain_extract.invoke({\"page_data\": page_data})\n",
    "print(response.content)\n",
    "# its power of llm - it can extract key information among the all the clutter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sH-3_U0UFPQ9",
    "outputId": "d246564b-7035-4fad-d2c0-a4ae2e8f20f1"
   },
   "outputs": [],
   "source": [
    "# Converting str into Json\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "json_parser = JsonOutputParser()\n",
    "json_res = json_parser.parse(response.content)\n",
    "print(json_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Rlal9zUCFPUM",
    "outputId": "6e0cb5c5-2654-430a-92f8-d70c903942d6"
   },
   "outputs": [],
   "source": [
    "print(type(json_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 696
    },
    "id": "8QB5bcf6QrhJ",
    "outputId": "21e1bf7e-89b9-4faa-89e1-de42c62edbf7"
   },
   "outputs": [],
   "source": [
    "# Reading CSV for upload a portfolio\n",
    "import pandas as pd\n",
    "df = pd.read_csv('my_portfolio.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2ZNmJPd4n-1o",
    "outputId": "f3bf27bc-1062-46a8-91d6-86765faf29f3"
   },
   "outputs": [],
   "source": [
    "# Iterating the dataframe one by one and add information to chromadb\n",
    "import uuid\n",
    "import chromadb\n",
    "client = chromadb.PersistentClient('vectorstore')\n",
    "#When use persistent client, it will create a folder called vector store vectore details\n",
    "collection = client.get_or_create_collection(name='my_portfolio')\n",
    "\n",
    "if not collection.count():\n",
    "  for _, row in df.iterrows():\n",
    "    collection.add(documents=row['Techstack'],\n",
    "                    metadatas = {\"links\":row[\"Links\"]},\n",
    "                    ids = [str(uuid.uuid4())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GSO83YWko1lR",
    "outputId": "57f070c5-bba3-4251-c342-acd54d7c67b5"
   },
   "outputs": [],
   "source": [
    "links = collection.query(query_texts = ['Experience in python ', \"Expertise in React Native\"], n_results=2).get(\"metadata\",[])\n",
    "links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YUNVRXERo5ri",
    "outputId": "50aa3dd1-308d-40fd-debc-c2b400032a1e"
   },
   "outputs": [],
   "source": [
    "collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job = json_res\n",
    "job['skills']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 181
    },
    "id": "s9eDyWWqv1id",
    "outputId": "5b2226db-bbf4-42bc-cc9d-7d6fe24e2a2a"
   },
   "outputs": [],
   "source": [
    "links = collection.query(query_texts=job['skills'], n_results=2).get('metadatas', [])\n",
    "links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0vZ8lLMXyMUt"
   },
   "outputs": [],
   "source": [
    "prompt_email = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    ### JOB DESCRIPTION:\n",
    "    {job_description}\n",
    "\n",
    "    ### INSTRUCTION:\n",
    "    You are Sivaranjani, a business development at xxx company, xxx company is an AI & Software consulting company dedicated to the seamless integration\n",
    "    of business processes through automated tools.\n",
    "    Over our experience, we have empowered numerous enterprises with tailored solutions, fostering scalablity, process optimization, cost reduction,\n",
    "    and heightened overall efficiency.\n",
    "    Your job is to write a cold email to the client regarding the job mentioned above describing the capablity of xxx in fulfilled their needs.\n",
    "    Also add the most relevent ones from the following links to showcase xxx's portfolio : {link_list}\n",
    "    Remember you are Sivaranjani, BDE at xxx.\n",
    "    Do not provide a preambel.\n",
    "    ### EMAIL (NO PREAMBLE):\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_email = prompt_email | llm\n",
    "res = chain_email.invoke({'job_description' : str(job), \"link_list\":links })\n",
    "print(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
